{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demystifying Markov Chain Monte Carlo\n",
    "\n",
    "#### Brett Morris\n",
    "\n",
    "### In this tutorial \n",
    "\n",
    "We will write our own Markov Chain Monte Carlo algorithm with a Metropolis-Hastings sampler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the properties of the line that we'll be fitting: \n",
    "true_slope = 0.3\n",
    "true_intercept = 0.0\n",
    "\n",
    "x = np.linspace(0, 10, 50)\n",
    "y = np.random.randn(len(x)) + true_slope * x + true_intercept\n",
    "yerr = np.random.rand(len(x))/10 + 1\n",
    "\n",
    "plt.errorbar(x, y, yerr, fmt='.')\n",
    "plt.plot(x, true_slope * x + true_intercept, color='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a simple linear model to describe the data, which has parameters $\\theta = \\{m, b\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_model(theta, x): \n",
    "    \"\"\"\n",
    "    Simple linear model. \n",
    "    \"\"\"\n",
    "    m, b = theta\n",
    "    return m * x + b\n",
    "\n",
    "\n",
    "def chi2(theta, x, y, yerr, model): \n",
    "    \"\"\"\n",
    "    Compute the \\chi^2 by comparing `model` evaluated at `theta`\n",
    "    to `y` at each value of `x`. \n",
    "    \"\"\"\n",
    "    return np.sum((model(theta, x) - y)**2 / yerr**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the proposal step simply draw from a Gaussian distribution:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proposal(theta, scale=1):\n",
    "    \"\"\"\n",
    "    Generate proposal step, by adding a draw from a \n",
    "    Gaussian distribution to the initial step position\n",
    "    \"\"\"\n",
    "    return theta + scale * np.random.randn(len(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will decide whether or not to accept new proposal steps using the Metropolis-Hastings algorithm, as defined by [Ford (2005)](https://arxiv.org/abs/astro-ph/0305441):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def metropolis_hastings(init_theta, x, y, yerr, acceptance, scale=0.05):\n",
    "    \"\"\"\n",
    "    Metropolis-Hastings algorithm, a la Ford (2005). \n",
    "    \n",
    "    1) Generate a proposal step\n",
    "    2) Compare the chi^2 of the proposal step to the current step\n",
    "    3) Draw a random number `u` on [0, 1]\n",
    "    4) Compute alpha = min([exp(-0.5 * (chi2(new) - chi2(old)), 1])\n",
    "    5) If u <= alpha, accept step, otherwise keep step\n",
    "    6) Return to step (1)\n",
    "    \"\"\"\n",
    "    # Generate a proposal step: \n",
    "    proposed_theta = proposal(init_theta, scale=scale)\n",
    "\n",
    "    # Compare chi^2 of proposed step to current step:\n",
    "    chi2_init_step = chi2(init_theta, x, y, yerr, linear_model)\n",
    "    chi2_proposed_step = chi2(proposed_theta, x, y, yerr, linear_model)\n",
    "    relative_likelihood = np.exp(-0.5 * (chi2_proposed_step - chi2_init_step))\n",
    "    \n",
    "    alpha = np.min([relative_likelihood, 1])\n",
    "\n",
    "    # If U(0, 1) <= alpha, accept the step: \n",
    "    if np.random.rand() <= alpha: \n",
    "        return proposed_theta, acceptance + 1\n",
    "    else: \n",
    "        return init_theta, acceptance\n",
    "    \n",
    "\n",
    "def sampler(x, y, yerr, init_theta, n_steps, scale=0.05):\n",
    "    \"\"\"\n",
    "    Markov Chain Monte Carlo sampler. \n",
    "    \"\"\"\n",
    "    current_theta = np.copy(init_theta)\n",
    "    # Allocate memory for samples: \n",
    "    samples = np.zeros((n_steps, len(init_theta)))\n",
    "    samples[0, :] = init_theta\n",
    "    acceptance = 0\n",
    "    \n",
    "    for i in range(1, n_steps):\n",
    "        # Run the M-H algorithm to determine next step:\n",
    "        current_theta, acceptance = metropolis_hastings(current_theta, \n",
    "                                                        x, y, yerr, acceptance, \n",
    "                                                        scale=scale)\n",
    "        # Record the result: \n",
    "        samples[i, :] = current_theta\n",
    "        \n",
    "    # Compute the final acceptance rate\n",
    "    acceptance_rate = acceptance / n_steps\n",
    "    \n",
    "    return samples, acceptance_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an initial guess (which is wrong!) and let the MCMC algorithm find the correct solution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_parameters = [1, 0.5]  # slope, intercept\n",
    "n_steps = 50000\n",
    "\n",
    "# This tweakable parameter determines how\n",
    "# far new steps should be taken away from \n",
    "# previous steps. Increase `scale` to \n",
    "# decrease your acceptance rate: \n",
    "scale = 0.06\n",
    "\n",
    "samples, acceptance_rate = sampler(x, y, yerr, init_parameters, \n",
    "                                   n_steps, scale=scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the acceptance rate? Ideally this should be near 45%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(acceptance_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a few random draws from the posterior probability distribution functions for each parameter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(100): \n",
    "    random_step = np.random.randint(0, samples.shape[0])\n",
    "    random_theta = samples[random_step, :]\n",
    "    plt.plot(x, linear_model_1(random_theta, x), alpha=0.05, color='k')\n",
    "plt.errorbar(x, y, yerr, fmt='.')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the uncertainty in the measurements is being reflected by uncertainty in the slope and intercept parameters. \n",
    "\n",
    "We normally see the posterior probability distribution functions displayed in a \"corner\" plot like the one below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from corner import corner\n",
    "\n",
    "burned_in_samples = samples[1000:]\n",
    "\n",
    "corner(burned_in_samples, labels=['m', 'b'], truths=[true_slope, true_intercept]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the posterior distributions are consistent within the uncertainties for each parameter! We are accurately measuring each parameter and their uncertainties. \n",
    "\n",
    "### Parameter Degeneracies\n",
    "\n",
    "But these parameters $m$ and $b$ are correlated with one another – note that small values of $m$ correspond to large values of $b$ while small values of $b$ correspond to large values of $m$. We can get rid of this degeneracy by reparameterizing our model to fit for the parameters $\\theta$ and $b$, see [Hogg et al. (2010)](https://arxiv.org/abs/1008.4686). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
